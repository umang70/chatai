ğŸŒ AI Chatbot with Groq + web Search + Memory

A lightweight and powerful AI chatbot built using Groq LLM, Tavily Web Search, and NodeCache conversation memory.
Supports real-time web search, tool calling, and thread-based memory.

ğŸš€ Features

ğŸ” Real-time web search using Tavily .


ğŸ§  Per-thread memory (remembers past messages for 24 hours)

ğŸ¤– Groq Llama 3.1 model for fast responses

âš™ï¸ Automatic tool calling (LLM decides when to search the web)

ğŸª¶ Clean, modular code

ğŸ” Simple generate(message, threadId) function for easy integration

ğŸ“¦ Installation
1ï¸âƒ£ Clone the repo
git clone https://github.com/yourusername/your-repo.git
cd your-repo

2ï¸âƒ£ Install dependencies
npm install

3ï¸âƒ£ Create .env file
GROQ_API_KEY=your_groq_key
TAVILY_API_KEY=your_tavily_key


Get keys:

Groq key â†’ https://console.groq.com/keys

Tavily key â†’ https://app.tavily.com/api-key

ğŸ§© Project Structure
/project
â”‚â”€â”€ index.js       # main server file (optional)
â”‚â”€â”€ chatbot.js     # your chatbot logic (Groq + Tavily + memory)
â”‚â”€â”€ package.json
â”‚â”€â”€ .env
â”‚â”€â”€ README.md

ğŸ”¥ How to Use the Chatbot
Import and call the generate() function:
import { generate } from "./chatbot.js";

const reply = await generate("What is the price of iPhone 16?", "user1");
console.log(reply);

Clear memory:
import { clearMemory } from "./chatbot.js";

clearMemory("user1");

ğŸ§  Conversation Memory

Memory is stored using NodeCache

Each threadId has its own private history

Auto-expires after 24 hours

You can create multiple user sessions:

generate("hello", "userA");
generate("hello", "userB");

ğŸŒ How Web Search Works

The LLM decides automatically when it needs web search using the tool_calls feature.

If it requests:

{ "name": "webSearch", "arguments": { "query": "something" } }


â†’ your code runs webSearch()
â†’ gives fresh info back to the model
â†’ second pass generates a final answer

ğŸ“¡ Example API Endpoint

If you want a simple Express server:

import express from "express";
import { generate } from "./chatbot.js";

const app = express();
app.use(express.json());

app.post("/chat", async (req, res) => {
  const { message, threadId } = req.body;

  const reply = await generate(message, threadId || "default");
  res.json({ reply });
});

app.listen(4300, () => console.log("Server running on 4300"));<img width="2816" height="1536" alt="flow-chart" src="https://github.com/user-attachments/assets/66dbf0fc-c5d8-4c41-80b3-ebc499c1d56c" />


ğŸ› ï¸ Technologies Used

Node.js

Groq SDK

Tavily Search

NodeCache


Tool Calling Architecture

ğŸ¤ Contributing

Feel free to submit PRs or issues.


